{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install rascal:\n",
    "(NOTE: See the top-level README for the most up-to-date installation instructions.)\n",
    "+ mkdir ../build \n",
    "+ cd build\n",
    "+ cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=ON ..\n",
    "+ make -j 4\n",
    "+ make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import os, sys\n",
    "from ase.io import read\n",
    "sys.path.insert(0,\"../build/\")\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import rascal\n",
    "import json\n",
    "\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from ase.build import make_supercell\n",
    "from ase.visualize import view\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from rascal.representations import SphericalInvariants\n",
    "from rascal.models import Kernel, KRR, train_gap_model, SparsePoints\n",
    "from rascal.utils import from_dict, to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# # a collection of distorted ethanol molecules from the ANI-1 dataset \n",
    "# # (see https://github.com/isayev/ANI1_dataset) with energies and forces computed using DFTB+ \n",
    "# # (see https://www.dftbplus.org/)\n",
    "# url = 'https://raw.githubusercontent.com/cosmo-epfl/librascal-example-data/833b4336a7daf471e16993158322b3ea807b9d3f/inputs/molecule_conformers_dftb.xyz'\n",
    "# # Download the file from `url`, save it in a temporary directory and get the\n",
    "# # path to it (e.g. '/tmp/tmpb48zma.txt') in the `structures_fn` variable:\n",
    "# structures_fn, headers = urllib.request.urlretrieve(url)\n",
    "# structures_fn\n",
    "structures_fn = '/tmp/tmpiilc84vk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical Invariants: body order = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     19,
     38
    ]
   },
   "outputs": [],
   "source": [
    "def extract_ref(frames,info_key='dft_formation_energy_per_atom_in_eV',array_key='zeros'):\n",
    "    y,f = [], []\n",
    "    for frame in frames:\n",
    "        y.append(frame.info[info_key])\n",
    "        if array_key is None:\n",
    "            pass\n",
    "        elif array_key == 'zeros':\n",
    "            f.append(np.zeros(frame.get_positions().shape))\n",
    "        else:\n",
    "            f.append(frame.get_array(array_key))\n",
    "    y= np.array(y)\n",
    "    try:\n",
    "        f = np.concatenate(f)\n",
    "    except:\n",
    "        pass\n",
    "    return y,f\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def get_r2(y_pred,y_true):\n",
    "    weight = 1\n",
    "    sample_weight = None\n",
    "    numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,dtype=np.float64)\n",
    "    denominator = (weight * (y_true - np.average(\n",
    "        y_true, axis=0, weights=sample_weight)) ** 2).sum(axis=0,dtype=np.float64)\n",
    "    output_scores = 1 - (numerator / denominator)\n",
    "    return np.mean(output_scores)\n",
    "\n",
    "def get_mae(ypred,y):\n",
    "    return np.mean(np.abs(ypred-y))\n",
    "def get_rmse(ypred,y):\n",
    "    return np.sqrt(np.mean((ypred-y)**2))\n",
    "def get_sup(ypred,y):\n",
    "    return np.amax(np.abs((ypred-y)))\n",
    "def get_spearman(ypred,y):\n",
    "    corr,_ = spearmanr(ypred,y)\n",
    "    return corr\n",
    "\n",
    "score_func = dict(\n",
    "    MAE=get_mae,\n",
    "    RMSE=get_rmse,\n",
    "    SUP=get_sup,\n",
    "    R2=get_r2,\n",
    "    CORR=get_spearman\n",
    ")\n",
    "\n",
    "def get_score(ypred,y):\n",
    "    scores = {}\n",
    "    for k,func in score_func.items():\n",
    "        scores[k] = func(ypred,y)\n",
    "    return scores\n",
    "def print_score(ypred,y):\n",
    "    scores = get_score(ypred,y)\n",
    "    print(' '.join(map(lambda x:'{}={:.2e}'.format(*x), scores.items())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## compute the representation of some atomic structures and their similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the small molecules \n",
    "frames = read('../reference_data/inputs/small_molecules-1000.xyz',':100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=3.5, \n",
    "              max_radial=1, \n",
    "              max_angular=1, \n",
    "              gaussian_sigma_constant=0.4,\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              normalize=True,\n",
    "              )\n",
    "soap = SphericalInvariants(**hypers)\n",
    "zeta=1\n",
    "kernel1 = Kernel(soap,name='Cosine', zeta=zeta, target_type='Structure', kernel_type='Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "frames[0].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "representation = soap.transform(frames)\n",
    "X = representation.get_features(soap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "kk = np.power(np.dot(X, X.T), zeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## identify the most important features for regression with standard KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_krr_model(kernel, managers, K_, y_train, sigma=1e-3, jitter=1e-8):\n",
    "    Y = y_train.reshape((-1, 1)).copy()\n",
    "    K = K_.copy()\n",
    "    n_centers = Y.shape[0]\n",
    "    Natoms = np.zeros(n_centers)\n",
    "    Y0 = np.zeros((n_centers, 1))\n",
    "    for iframe, manager in enumerate(managers):\n",
    "        Natoms[iframe] = len(manager)\n",
    "    delta = np.std(Y)\n",
    "    # K[np.diag_indices_from(K)] *= (sigma / delta)**2 * Natoms + jitter\n",
    "    K[np.diag_indices_from(K)] *= (sigma / delta)**2 + jitter\n",
    "    weights = np.linalg.lstsq(K, Y, rcond=None)[0]\n",
    "    model = KRR(weights, kernel, managers, {sp:0. for sp in range(120)})\n",
    "\n",
    "    # avoid memory clogging\n",
    "    del K\n",
    "    K = []\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Total number of structure to load\n",
    "N = 985\n",
    "# Number of structure to train the model with\n",
    "f = int(0.6*N)\n",
    "\n",
    "# load the structures\n",
    "frames = read('../reference_data/inputs/small_molecules-1000.xyz',':{}'.format(N))\n",
    "\n",
    "\n",
    "global_species = []\n",
    "for frame in frames:\n",
    "    global_species.extend(frame.get_atomic_numbers())\n",
    "global_species = np.unique(global_species)\n",
    "\n",
    "# split the structures in 2 sets\n",
    "ids = list(range(N))\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "frames_train = [frames[ii] for ii in ids[:f]]\n",
    "frames_test = [frames[ii] for ii in ids[f:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split the dataset in a train and a test set\n",
    "y_train, _ = extract_ref(frames_train,'dft_formation_energy_per_atom_in_eV')\n",
    "for ii,ft in enumerate(frames_train):\n",
    "    y_train[ii] /= len(ft)\n",
    "y_test, _ = extract_ref(frames_test,'dft_formation_energy_per_atom_in_eV')\n",
    "for ii,ft in enumerate(frames_test):\n",
    "    y_test[ii] /= len(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=3.5, \n",
    "              max_radial=8, \n",
    "              max_angular=8, \n",
    "              gaussian_sigma_constant=0.4,\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              normalize=True,\n",
    "              expansion_by_species_method='structure wise',\n",
    "              )\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap,name='Cosine', zeta=2, target_type='Structure', kernel_type='Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers_train = soap.transform(frames_train)\n",
    "managers_test = soap.transform(frames_test)\n",
    "%time K = kernel(managers_train, managers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train a KRR model\n",
    "model = train_krr_model(kernel, managers_train, K, y_train, sigma=0.5e-1, jitter=1e-8)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(managers_test)\n",
    "\n",
    "# basic assessement of the quality of the trained model\n",
    "print_score(y_pred, y_test)\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.title(\"correlation plot\")\n",
    "plt.ylabel(\"predicted energies [eV]\")\n",
    "plt.xlabel(\"reference energies [eV]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsification with the gap model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     91,
     150,
     204
    ]
   },
   "outputs": [],
   "source": [
    "from rascal.utils import BaseIO\n",
    "from rascal.models import SparsePoints\n",
    "\n",
    "from rascal.lib import sparsification\n",
    "from rascal.utils.filter_utils import (get_index_mappings_sample_per_species,\n",
    "                           convert_selected_global_index2rascal_sample_per_species,\n",
    "                           get_index_mappings_sample,\n",
    "                           convert_selected_global_index2rascal_sample)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n",
    "def do_CUR(X, Nsel, act_on='sample', is_deterministic=False, seed=10, verbose=True):\n",
    "    \"\"\" Apply CUR selection [1] of Nsel rows or columns of the\n",
    "    given feature matrix X[n_samples, n_features].\n",
    "\n",
    "    .. [1] Mahoney, M. W., & Drineas, P. (2009). CUR matrix decompositions for\n",
    "    improved data analysis. Proceedings of the National Academy of Sciences,106(3),\n",
    "    697–702. https://doi.org/10.1073/pnas.0803205106\n",
    "    \"\"\"\n",
    "    U, _, VT = svds(X, Nsel)\n",
    "    if 'sample' in act_on:\n",
    "        weights = np.mean(np.square(U), axis=1)\n",
    "    elif 'feature' in act_on:\n",
    "        weights = np.mean(np.square(VT), axis=0)\n",
    "    if is_deterministic is True:\n",
    "        # sorting is smallest to largest hence the minus\n",
    "        sel = np.argsort(-weights)[:Nsel]\n",
    "    elif is_deterministic is False:\n",
    "        np.random.seed(seed)\n",
    "        # sorting is smallest to largest hence the minus\n",
    "        sel = np.argsort(np.random.rand(*weights.shape) - weights)[:Nsel]\n",
    "\n",
    "    if verbose is True:\n",
    "        if 'sample' in act_on:\n",
    "            C = X[sel, :]\n",
    "            Cp = np.linalg.pinv(C)\n",
    "            err = np.sqrt(np.sum((X - np.dot(np.dot(X, Cp), C))**2))\n",
    "        elif 'feature' in act_on:\n",
    "            C = X[:, sel]\n",
    "            Cp = np.linalg.pinv(C)\n",
    "            err = np.sqrt(np.sum((X - np.dot(C, np.dot(Cp, X)))**2))\n",
    "\n",
    "        print('Reconstruction RMSE={:.3e}'.format(err))\n",
    "\n",
    "    return sel\n",
    "\n",
    "\n",
    "class CURFilter(BaseIO):\n",
    "    \"\"\"CUR decomposition to select samples or features in a given feature matrix.\n",
    "    Wrapper around the do_CUR function for convenience.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    representation : Calculator\n",
    "        Representation calculator associated with the kernel\n",
    "\n",
    "    Nselect: int\n",
    "        number of points to select. if act_on='sample per species' then it should\n",
    "        be a dictionary mapping atom type to the number of samples, e.g.\n",
    "        Nselect = {1:200,6:100,8:50}.\n",
    "\n",
    "    act_on: string\n",
    "        Select how to apply the selection. Can be either of 'sample',\n",
    "        'sample per species','feature'.\n",
    "        For the moment only 'sample per species' is implemented.\n",
    "\n",
    "    is_deterministic: bool\n",
    "        flag to switch between selction criteria\n",
    "\n",
    "    seed: int\n",
    "        if is_deterministic==False, seed for the random selection\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, representation, Nselect, act_on='sample per species',\n",
    "                                                is_deterministic=True, seed=10):\n",
    "        self._representation = representation\n",
    "        self.Nselect = Nselect\n",
    "        if act_on in ['sample', 'sample per species', 'feature']:\n",
    "            self.act_on = act_on\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                '\"act_on\" should be either of: \"{}\", \"{}\", \"{}\"'.format(\n",
    "                    *['sample', 'sample per species', 'feature']))\n",
    "        self.is_deterministic = is_deterministic\n",
    "        self.seed = seed\n",
    "        self.selected_ids = None\n",
    "        self.selected_ids_by_sp = None\n",
    "        self.selected_ids_global = None\n",
    "\n",
    "        \n",
    "    def fit(self, managers):\n",
    "        \"\"\"Perform CUR selection of samples/features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        managers : AtomsList\n",
    "            list of structures containing features computed with representation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        SparsePoints\n",
    "            Selected samples\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            [description]\n",
    "        NotImplementedError\n",
    "            [description]\n",
    "        \"\"\"\n",
    "        # get the dense feature matrix\n",
    "        X = managers.get_features(self._representation)\n",
    "\n",
    "        if self.act_on in ['sample per species']:\n",
    "            sps = list(self.Nselect.keys())\n",
    "\n",
    "            # get various info from the structures about the center atom species and indexing\n",
    "            (strides_by_sp, global_counter, map_by_manager,\n",
    "             indices_by_sp) = get_index_mappings_sample_per_species(managers, sps)\n",
    "\n",
    "            print('The number of pseudo points selected by central atom species is: {}'.format(\n",
    "                self.Nselect))\n",
    "\n",
    "            # organize features w.r.t. central atom type\n",
    "            X_by_sp = {}\n",
    "            for sp in sps:\n",
    "                X_by_sp[sp] = X[indices_by_sp[sp]]\n",
    "            self._XX = X_by_sp\n",
    "\n",
    "            # split the dense feature matrix by center species and apply CUR decomposition\n",
    "            self.selected_ids_by_sp = {}\n",
    "            self.fps_minmax_d2_by_sp = {}\n",
    "            self.fps_hausforff_d2_by_sp = {}\n",
    "            for sp in sps:\n",
    "                print('Selecting species: {}'.format(sp))\n",
    "                self.selected_ids_by_sp[sp] = do_CUR(X_by_sp[sp], self.Nselect[sp], self.act_on,\n",
    "                                                        self.is_deterministic, self.seed)\n",
    "\n",
    "        elif self.act_on in ['sample']:\n",
    "            self.selected_ids = do_CUR(X, self.Nselect, self.act_on,\n",
    "                                               self.is_deterministic, self.seed)\n",
    "        elif self.act_on in ['feature']:                                                \n",
    "            self.selected_ids = do_CUR(X, self.Nselect, self.act_on,\n",
    "                                                        self.is_deterministic, self.seed)\n",
    "        else:\n",
    "            raise ValueError(\"method: {}\".format(self.act_on))\n",
    "                    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, managers, n_select=None):\n",
    "        if n_select is None:\n",
    "            n_select = self.Nselect\n",
    "            \n",
    "        if self.act_on in ['sample per species']:\n",
    "            sps = list(n_select.keys())\n",
    "            # get various info from the structures about the center atom species and indexing\n",
    "            (strides_by_sp, global_counter, map_by_manager,\n",
    "             indices_by_sp) = get_index_mappings_sample_per_species(managers, sps)\n",
    "            selected_ids_by_sp = {key: np.sort(val[:n_select[key]])\n",
    "                                  for key, val in self.selected_ids_by_sp.items()}\n",
    "            self.selected_ids = convert_selected_global_index2rascal_sample_per_species(\n",
    "                managers, selected_ids_by_sp, strides_by_sp, map_by_manager, sps)\n",
    "            # return self.selected_ids\n",
    "            # build the pseudo points\n",
    "            pseudo_points = SparsePoints(self._representation)\n",
    "            pseudo_points.extend(managers, self.selected_ids)\n",
    "            return pseudo_points\n",
    "        \n",
    "        elif self.act_on in ['sample']:\n",
    "            selected_ids_global = np.sort(self.selected_ids_global[:n_select])\n",
    "            strides, _, map_by_manager = get_index_mappings_sample(managers)\n",
    "            self.selected_ids = convert_selected_global_index2rascal_sample(managers,\n",
    "                                                selected_ids_global, strides, map_by_manager)\n",
    "            return self.selected_ids\n",
    "            # # build the pseudo points\n",
    "            # pseudo_points = SparsePoints(self._representation)\n",
    "            # pseudo_points.extend(managers, self.selected_ids)\n",
    "            # return pseudo_points\n",
    "\n",
    "        elif self.act_on in ['feature']:\n",
    "            feat_idx2coeff_idx = self._representation.get_feature_index_mapping(\n",
    "                managers)\n",
    "            selected_features = {key: []\n",
    "                                 for key in feat_idx2coeff_idx[0].keys()}\n",
    "            selected_ids_sorting = np.argsort(self.selected_ids[:n_select])\n",
    "            selected_ids = self.selected_ids[selected_ids_sorting]\n",
    "            for idx in selected_ids:\n",
    "                coef_idx = feat_idx2coeff_idx[idx]\n",
    "                for key in selected_features.keys():\n",
    "                    selected_features[key].append(int(coef_idx[key]))\n",
    "            # keep the global indices and ordering for ease of use\n",
    "            selected_features['selected_features_global_ids'] = selected_ids.tolist()\n",
    "            selected_features['selected_features_global_ids_fps_ordering'] = selected_ids_sorting.tolist()\n",
    "            return dict(coefficient_subselection=selected_features)\n",
    "            \n",
    "    def fit_transform(self, managers):\n",
    "        return self.fit(managers).transform(managers)\n",
    "    def _get_data(self):\n",
    "        return dict(selected_ids=self.selected_ids, \n",
    "                    selected_ids_by_sp=self.selected_ids_by_sp,\n",
    "                   selected_ids_global=self.selected_ids_global)\n",
    "\n",
    "    def _set_data(self, data):\n",
    "        self.selected_ids = data['selected_ids']\n",
    "        self.selected_ids_by_sp = data['selected_ids_by_sp']\n",
    "        self.selected_ids_global = data['selected_ids_global']\n",
    "    def _get_init_params(self):\n",
    "        return dict(representation=self._representation,\n",
    "                    Nselect=self.Nselect,\n",
    "                    act_on=self.act_on,\n",
    "                    is_deterministic=self.is_deterministic,\n",
    "                    seed=self.seed,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     120,
     180
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def fps(feature_matrix, n_select, starting_index=None,\n",
    "        method='simple', restart=None):\n",
    "    \"\"\"\n",
    "    Farthest Point Sampling [1] routine using librascal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix : numpy.ndarray[float64[n, m], flags.c_contiguous]\n",
    "        Feature matrix with n samples and m features.\n",
    "    n_select : int\n",
    "        Number of sample to select\n",
    "    starting_index : int, optional\n",
    "        Index of the first sample to select (the default is None,\n",
    "                           which corresponds to starting_index == 0)\n",
    "    restart : dictionary, optional (only valid for method=\"simple\")\n",
    "        the return value of a previous call to FPS. the selection\n",
    "        will continue where it has been left off. the dictionary\n",
    "        should contain at least \"fps_indices\"; if \"fps_minmax_d2\" and\n",
    "        \"fps_hausdorff_d2\" are present, they will be used to restart,\n",
    "        otherwise they'll be recomputed\n",
    "\n",
    "    method : str, optional\n",
    "        Select which kind of FPS selection to perform:\n",
    "        + 'simple' is the basic fps selection [1].\n",
    "        + 'voronoi' uses voronoi polyhedra to avoid some\n",
    "                    distance computations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary containing the following quantities\n",
    "    \"fps_indices\" : numpy.ndarray[int[n_select]]\n",
    "        Selected indices refering to the feature_matrix order.\n",
    "    \"fps_minmax_d2\": numpy.ndarray[float64[n_select]]\n",
    "        MIN-MAX distance^2 at each step in the selection\n",
    "    \"fps_hausforff_d2\": numpy.ndarray[float64[n]]\n",
    "        array of Hausdorff distances between the n points and the\n",
    "        n_select FPS points\n",
    "    In addition, when method=\"voronoi\", the following arrays are returned\n",
    "    \"fps_voronoi_indices\": numpy.ndarray[int[n]]\n",
    "        the indices that assign each of the n inputs to the closest FPS point\n",
    "    \"fps_voronoi_r2\": numpy.ndarray[float64[n_select]]\n",
    "        the squared \"Voronoi radius\" of each FPS point (the largest distance to\n",
    "        one of the points associated to its Voronoi cell\n",
    "\n",
    "\n",
    "    .. [1] Ceriotti, M., Tribello, G. A., & Parrinello, M. (2013).\n",
    "        Demonstrating the Transferability and the Descriptive Power of Sketch-Map.\n",
    "        Journal of Chemical Theory and Computation, 9(3), 1521–1532.\n",
    "        https://doi.org/10.1021/ct3010563\n",
    "    \"\"\"\n",
    "\n",
    "    if starting_index is None:\n",
    "        starting_index = 0\n",
    "\n",
    "    return_dict = {}\n",
    "    if method == 'simple':\n",
    "        if restart is None:\n",
    "            sparse_indices, sparse_minmax_d2, lmin_d2 = \\\n",
    "                sparsification.fps(feature_matrix, n_select, starting_index)\n",
    "        else:\n",
    "            res_tuple = (restart[\"fps_indices\"],\n",
    "                         (restart[\"fps_minmax_d2\"] if \"fps_minmax_d2\" in restart\n",
    "                          else np.zeros(0, float)),\n",
    "                         (restart[\"fps_hausdorff_d2\"] if \"fps_hausdorff_d2\" in restart\n",
    "                          else np.zeros(0, float)))\n",
    "            sparse_indices, sparse_minmax_d2, lmin_d2 = \\\n",
    "                sparsification.fps(feature_matrix, n_select,\n",
    "                                   starting_index, res_tuple)\n",
    "\n",
    "    elif method == 'voronoi':\n",
    "        sparse_indices, sparse_minmax_d2, lmin_d2, \\\n",
    "            voronoi_indices, voronoi_r2 = \\\n",
    "            sparsification.fps_voronoi(feature_matrix,\n",
    "                                       n_select, starting_index)\n",
    "        return_dict[\"fps_voronoi_indices\"] = voronoi_indices\n",
    "        return_dict[\"fps_voronoi_r2\"] = voronoi_r2\n",
    "\n",
    "    else:\n",
    "        raise Exception('Unknown FPS algorithm {}'.format(method))\n",
    "\n",
    "    return_dict[\"fps_indices\"] = sparse_indices\n",
    "    return_dict[\"fps_minmax_d2\"] = sparse_minmax_d2\n",
    "    return_dict[\"fps_hausdorff_d2\"] = lmin_d2\n",
    "\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "class FPSFilter(BaseIO):\n",
    "    \"\"\"Farther Point Sampling (FPS) to select samples or features in a given feature matrix.\n",
    "    Wrapper around the fps function for convenience.\n",
    "    Parameters\n",
    "    ----------\n",
    "    representation : Calculator\n",
    "        Representation calculator associated with the kernel\n",
    "    Nselect: int\n",
    "        number of points to select. if act_on='sample per specie' then it should\n",
    "        be a dictionary mapping atom type to the number of samples, e.g.\n",
    "        Nselect = {1:200,6:100,8:50}.\n",
    "    act_on: string\n",
    "        Select how to apply the selection. Can be either of 'sample',\n",
    "        'sample per species','feature'.\n",
    "    starting_index: int\n",
    "        Index used to start the FPS selection with.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, representation, Nselect, act_on='sample per species', starting_index=0):\n",
    "        self._representation = representation\n",
    "        self.Nselect = Nselect\n",
    "        self.starting_index = starting_index\n",
    "        if act_on in ['sample', 'sample per species', 'feature']:\n",
    "            self.act_on = act_on\n",
    "        else:\n",
    "            raise 'Wrong input: {}'.format(act_on)\n",
    "\n",
    "        self.selected_ids = None\n",
    "        self.selected_ids_by_sp = None\n",
    "        self.selected_ids_global = None\n",
    "        self.fps_minmax_d2_by_sp = None\n",
    "        self.fps_minmax_d2 = None\n",
    "\n",
    "    def fit(self, managers):\n",
    "        \"\"\"Perform FPS selection of samples/features.\n",
    "        Parameters\n",
    "        ----------\n",
    "        managers : AtomsList\n",
    "            list of structures containing features computed with representation\n",
    "        Returns\n",
    "        -------\n",
    "        PseudoPoints\n",
    "            Selected samples\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            [description]\n",
    "        NotImplementedError\n",
    "            [description]\n",
    "        \"\"\"\n",
    "\n",
    "        # get the dense feature matrix\n",
    "        X = managers.get_features(self._representation)\n",
    "\n",
    "        if self.act_on in ['sample per species']:\n",
    "            sps = list(self.Nselect.keys())\n",
    "\n",
    "            # get various info from the structures about the center atom species and indexing\n",
    "            (strides_by_sp, global_counter, map_by_manager,\n",
    "             indices_by_sp) = get_index_mappings_sample_per_species(managers, sps)\n",
    "\n",
    "            print('The number of pseudo points selected by central atom species is: {}'.format(\n",
    "                self.Nselect))\n",
    "\n",
    "            # organize features w.r.t. central atom type\n",
    "            X_by_sp = {}\n",
    "            for sp in sps:\n",
    "                X_by_sp[sp] = X[indices_by_sp[sp]]\n",
    "            self._XX = X_by_sp\n",
    "\n",
    "            # split the dense feature matrix by center species and apply CUR decomposition\n",
    "            self.selected_ids_by_sp = {}\n",
    "            self.fps_minmax_d2_by_sp = {}\n",
    "            self.fps_hausforff_d2_by_sp = {}\n",
    "            for sp in sps:\n",
    "                print('Selecting species: {}'.format(sp))\n",
    "                fps_out = fps(X_by_sp[sp], self.Nselect[sp],\n",
    "                              starting_index=self.starting_index)\n",
    "                self.selected_ids_by_sp[sp] = fps_out['fps_indices']\n",
    "                self.fps_minmax_d2_by_sp[sp] = fps_out['fps_minmax_d2']\n",
    "\n",
    "            return self\n",
    "        elif self.act_on in ['feature']:\n",
    "            fps_out = fps(X.T, self.Nselect, starting_index=self.starting_index)\n",
    "            self.selected_ids = fps_out['fps_indices']\n",
    "            self.fps_minmax_d2 = fps_out['fps_minmax_d2']\n",
    "        elif self.act_on in ['sample']:\n",
    "            fps_out = fps(X, self.Nselect, starting_index=self.starting_index)\n",
    "            self.selected_ids_global = fps_out['fps_indices']\n",
    "            self.fps_minmax_d2 = fps_out['fps_minmax_d2']\n",
    "        else:\n",
    "            raise NotImplementedError(\"method: {}\".format(self.act_on))\n",
    "\n",
    "    def transform(self, managers, n_select=None):\n",
    "        if n_select is None:\n",
    "            n_select = self.Nselect\n",
    "            \n",
    "        if self.act_on in ['sample per species']:\n",
    "            sps = list(n_select.keys())\n",
    "            # get various info from the structures about the center atom species and indexing\n",
    "            (strides_by_sp, global_counter, map_by_manager,\n",
    "             indices_by_sp) = get_index_mappings_sample_per_species(managers, sps)\n",
    "            selected_ids_by_sp = {key: np.sort(val[:n_select[key]])\n",
    "                                  for key, val in self.selected_ids_by_sp.items()}\n",
    "            self.selected_ids = convert_selected_global_index2rascal_sample_per_species(\n",
    "                managers, selected_ids_by_sp, strides_by_sp, map_by_manager, sps)\n",
    "            # return self.selected_ids\n",
    "            # build the pseudo points\n",
    "            pseudo_points = SparsePoints(self._representation)\n",
    "            pseudo_points.extend(managers, self.selected_ids)\n",
    "            return pseudo_points\n",
    "        \n",
    "        elif self.act_on in ['sample']:\n",
    "            selected_ids_global = np.sort(self.selected_ids_global[:n_select])\n",
    "            strides, _, map_by_manager = get_index_mappings_sample(managers)\n",
    "            self.selected_ids = convert_selected_global_index2rascal_sample(managers,\n",
    "                                                                            selected_ids_global, strides, map_by_manager)\n",
    "            return self.selected_ids\n",
    "            # # build the pseudo points\n",
    "            # pseudo_points = SparsePoints(self._representation)\n",
    "            # pseudo_points.extend(managers, self.selected_ids)\n",
    "            # return pseudo_points\n",
    "\n",
    "        elif self.act_on in ['feature']:\n",
    "            feat_idx2coeff_idx = self._representation.get_feature_index_mapping(\n",
    "                managers)\n",
    "            selected_features = {key: []\n",
    "                                 for key in feat_idx2coeff_idx[0].keys()}\n",
    "            selected_ids_sorting = np.argsort(self.selected_ids[:n_select])\n",
    "            selected_ids = self.selected_ids[selected_ids_sorting]\n",
    "            for idx in selected_ids:\n",
    "                coef_idx = feat_idx2coeff_idx[idx]\n",
    "                for key in selected_features.keys():\n",
    "                    selected_features[key].append(int(coef_idx[key]))\n",
    "            # keep the global indices and ordering for ease of use\n",
    "            selected_features['selected_features_global_ids'] = selected_ids.tolist()\n",
    "            selected_features['selected_features_global_ids_fps_ordering'] = selected_ids_sorting.tolist()\n",
    "            return dict(coefficient_subselection=selected_features)\n",
    "    \n",
    "    def fit_transform(self, managers):\n",
    "        return self.fit(managers).transform(managers)\n",
    "    \n",
    "    def plot(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        if self.fps_minmax_d2_by_sp is None:\n",
    "            plt.semilogy(self.fps_minmax_d2, label=self.act_on)\n",
    "\n",
    "        else:\n",
    "            for sp in self.fps_minmax_d2_by_sp:\n",
    "                plt.semilogy(self.fps_minmax_d2_by_sp[sp],\n",
    "                             label='{} species {}'.format(self.act_on, sp))\n",
    "            plt.legend()\n",
    "        plt.title('FPSFilter')\n",
    "        plt.ylabel('fps minmax d^2')\n",
    "\n",
    "    def fit_transform(self, managers):\n",
    "        return self.fit(managers).transform(managers)\n",
    "    \n",
    "    def _get_data(self):\n",
    "        return dict(selected_ids=self.selected_ids, \n",
    "                    selected_ids_by_sp=self.selected_ids_by_sp,\n",
    "                   selected_ids_global=self.selected_ids_global)\n",
    "\n",
    "    def _set_data(self, data):\n",
    "        self.selected_ids = data['selected_ids']\n",
    "        self.selected_ids_by_sp = data['selected_ids_by_sp']\n",
    "        self.selected_ids_global = data['selected_ids_global']\n",
    "    def _get_init_params(self):\n",
    "        return dict(representation=self._representation,\n",
    "                    Nselect=self.Nselect,\n",
    "                    act_on=self.act_on,\n",
    "                    starting_index=self.starting_index,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Total number of structure to load\n",
    "N = 1000\n",
    "# Number of structure to train the model with\n",
    "f = int(0.6*N)\n",
    "\n",
    "# load the structures\n",
    "frames = read(structures_fn,':{}'.format(N))\n",
    "\n",
    "\n",
    "global_species = []\n",
    "for frame in frames:\n",
    "    global_species.extend(frame.get_atomic_numbers())\n",
    "global_species = np.unique(global_species)\n",
    "\n",
    "# split the structures in 2 sets\n",
    "ids = list(range(N))\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "frames_train = [frames[ii] for ii in ids[:f]]\n",
    "frames_test = [frames[ii] for ii in ids[f:]]\n",
    "# Isolated atom contributions\n",
    "self_contributions = {\n",
    "    1: -6.492647589968434,\n",
    "    6: -38.054950840332474,\n",
    "    8: -83.97955098636527,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in a train and a test set\n",
    "y_train, _ = extract_ref(frames_train,'dftb_energy_eV')\n",
    "y_test, _ = extract_ref(frames_test,'dftb_energy_eV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=3.5, \n",
    "              max_radial=8, \n",
    "              max_angular=8, \n",
    "              gaussian_sigma_constant=0.4,\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              normalize=True,\n",
    "              expansion_by_species_method='structure wise',\n",
    "              )\n",
    "soap_calculator = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap_calculator,name='GAP', zeta=2, target_type='Structure', kernel_type='Sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pick up randomly sparse points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Nenv = 0\n",
    "env_map = []\n",
    "for i_frame, frame in enumerate(frames):\n",
    "    Nenv += len(frame)\n",
    "    for i_env in range(len(frame)):\n",
    "        env_map.append((i_frame, i_env))\n",
    "Nenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "managers_train = soap_calculator.transform(frames_train)\n",
    "managers_test = soap_calculator.transform(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute the representation for all atomic structures\n",
    "managers = soap_calculator.transform(frames)\n",
    "\n",
    "fractions = (Nenv*np.array([0.4,0.3,0.2,0.1,0.05])).astype(int)\n",
    "scores = []\n",
    "for fraction in tqdm(fractions):\n",
    "    ids = np.array(range(Nenv))\n",
    "    np.random.seed(100)\n",
    "    np.random.shuffle(ids)\n",
    "    # randomly select atomic centers\n",
    "    selected_ids = [[] for _ in range(len(frames))]\n",
    "    for idx in ids[:fraction]:\n",
    "        i_frame, i_env = env_map[idx]\n",
    "        selected_ids[i_frame].append(i_env)\n",
    "    # initialize the sparse points with randomly selected \n",
    "    sparse_points = SparsePoints(soap_calculator)\n",
    "    sparse_points.extend(managers, selected_ids)\n",
    "    \n",
    "    KNM = kernel(managers_train, sparse_points)\n",
    "    \n",
    "    model = train_gap_model(kernel, managers_train, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "    y_pred = model.predict(managers_test)\n",
    "    \n",
    "    score = get_score(y_pred, y_test)\n",
    "    score.update(n_sparse_point=fraction)\n",
    "    scores.append(score)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pick sparse points with fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "managers_train = soap_calculator.transform(frames_train)\n",
    "managers_test = soap_calculator.transform(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sps = []\n",
    "for frame in frames:\n",
    "    sps.extend(frame.get_atomic_numbers())\n",
    "sps_u = np.unique(sps)\n",
    "sps_n = np.bincount(sps)\n",
    "Nenv = {sp:sps_n[sp] for sp in sps_u}\n",
    "Nenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fps_filter = FPSFilter(soap_calculator, Nenv, 'sample per species')\n",
    "fps_filter.fit(managers)\n",
    "fps_filter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "\n",
    "fractions = [0.4,0.3,0.2,0.1,0.05]\n",
    "scores = []\n",
    "for fraction in tqdm(fractions):\n",
    "    sparse_points = fps_filter.transform(managers, {sp:int(n*fraction) for sp,n in Nenv.items()})\n",
    "    KNM = kernel(managers_train, sparse_points)\n",
    "    model = train_gap_model(kernel, managers_train, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "    y_pred = model.predict(managers_test)\n",
    "    score = get_score(y_pred, y_test)\n",
    "    score.update(fraction=fraction)\n",
    "    scores.append(score)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fraction = 0.2\n",
    "sparse_points = fps_filter.transform(managers, {sp:int(n*fraction) for sp,n in Nenv.items()})\n",
    "KNM = kernel(managers_train, sparse_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train a GAP model \n",
    "model = train_gap_model(kernel, managers_train, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "y_pred = model.predict(managers_test)\n",
    "\n",
    "print_score(y_pred, y_test)\n",
    "\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.title(\"correlation plot\")\n",
    "plt.xlabel(\"predicted energies [eV]\")\n",
    "plt.ylabel(\"reference energies [eV]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try feature sparsification with FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "\n",
    "X = managers.get_features(soap_calculator)\n",
    "n_features = int(X.shape[1]*0.4)\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = []\n",
    "for frame in frames:\n",
    "    sps.extend(frame.get_atomic_numbers())\n",
    "sps_u = np.unique(sps)\n",
    "sps_n = np.bincount(sps)\n",
    "Nenv = {sp:int(sps_n[sp]*0.05) for sp in sps_u}\n",
    "print(Nenv)\n",
    "fps_filter = FPSFilter(soap_calculator, Nenv, 'sample per species')\n",
    "fps_filter.fit(managers)\n",
    "fps_filter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_filter = FPSFilter(soap_calculator, n_features, 'feature')\n",
    "feature_filter.fit(managers);\n",
    "feature_filter.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = list(reversed([1, 0.75, 0.5, 0.25, 0.125, 0.05, 0.01]))\n",
    "scores = []\n",
    "for fraction in tqdm(fractions):\n",
    "    selected_feature = feature_filter.transform(managers, int(n_features*fraction))\n",
    "    \n",
    "    hypers_sparse = deepcopy(hypers)\n",
    "    hypers_sparse.update(**selected_feature)\n",
    "    soap_calculator_sparse = SphericalInvariants(**hypers_sparse)\n",
    "    \n",
    "    kernel_sparse = Kernel(soap_calculator_sparse,name='GAP', zeta=2, target_type='Structure', kernel_type='Sparse')\n",
    "    \n",
    "    managers_sp = soap_calculator_sparse.transform(frames)\n",
    "    managers_train_sp = soap_calculator_sparse.transform(frames_train)\n",
    "    managers_test_sp = soap_calculator_sparse.transform(frames_test)\n",
    "    \n",
    "    fps_filter_sp = from_dict(to_dict(fps_filter))\n",
    "    fps_filter_sp._representation = soap_calculator_sparse\n",
    "    sparse_points = fps_filter_sp.transform(managers_sp)\n",
    "    \n",
    "    KNM = kernel_sparse(managers_train_sp, sparse_points)\n",
    "    model = train_gap_model(kernel_sparse, managers_train_sp, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "    y_pred = model.predict(managers_test_sp)\n",
    "    score = get_score(y_pred, y_test)\n",
    "    score.update(n_features=int(n_features*fraction))\n",
    "    scores.append(score)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pick sparse points with CUR decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "managers_train = soap_calculator.transform(frames_train)\n",
    "managers_test = soap_calculator.transform(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sps = []\n",
    "for frame in frames:\n",
    "    sps.extend(frame.get_atomic_numbers())\n",
    "sps_u = np.unique(sps)\n",
    "sps_n = np.bincount(sps)\n",
    "Nenv = {sp:int(sps_n[sp]*0.4) for sp in sps_u}\n",
    "Nenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cur_filter = CURFilter(soap_calculator, Nenv, 'sample per species')\n",
    "cur_filter.fit(managers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "\n",
    "fractions = [1, 0.75, 0.5, 0.25, 0.125]\n",
    "scores = []\n",
    "for fraction in tqdm(fractions):\n",
    "    sparse_points = cur_filter.transform(managers, {sp:int(n*fraction) for sp,n in Nenv.items()})\n",
    "    KNM = kernel(managers_train, sparse_points)\n",
    "    model = train_gap_model(kernel, managers_train, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "    y_pred = model.predict(managers_test)\n",
    "    score = get_score(y_pred, y_test)\n",
    "    score.update(fraction=fraction)\n",
    "    scores.append(score)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fraction = 0.2\n",
    "sparse_points = fps_filter.transform(managers, {sp:int(n*fraction) for sp,n in Nenv.items()})\n",
    "KNM = kernel(managers_train, sparse_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train a GAP model \n",
    "model = train_gap_model(kernel, managers_train, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "y_pred = model.predict(managers_test)\n",
    "\n",
    "print_score(y_pred, y_test)\n",
    "\n",
    "plt.plot(y_test, y_pred, 'o')\n",
    "plt.title(\"correlation plot\")\n",
    "plt.xlabel(\"predicted energies [eV]\")\n",
    "plt.ylabel(\"reference energies [eV]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try feature sparsification with CUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers = soap_calculator.transform(frames)\n",
    "\n",
    "X = managers.get_features(soap_calculator)\n",
    "n_features = int(X.shape[1]*0.4)\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = []\n",
    "for frame in frames:\n",
    "    sps.extend(frame.get_atomic_numbers())\n",
    "sps_u = np.unique(sps)\n",
    "sps_n = np.bincount(sps)\n",
    "Nenv = {sp:int(sps_n[sp]*0.05) for sp in sps_u}\n",
    "print(Nenv)\n",
    "cur_filter = CURFilter(soap_calculator, Nenv, 'sample per species')\n",
    "cur_filter.fit(managers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_filter = CURFilter(soap_calculator, n_features, 'feature')\n",
    "feature_filter.fit(managers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = list(reversed([1, 0.75, 0.5, 0.25, 0.125, 0.05, 0.01]))\n",
    "scores = []\n",
    "for fraction in tqdm(fractions):\n",
    "    selected_feature = feature_filter.transform(managers, int(n_features*fraction))\n",
    "    \n",
    "    hypers_sparse = deepcopy(hypers)\n",
    "    hypers_sparse.update(**selected_feature)\n",
    "    soap_calculator_sparse = SphericalInvariants(**hypers_sparse)\n",
    "    \n",
    "    kernel_sparse = Kernel(soap_calculator_sparse,name='GAP', zeta=2, target_type='Structure', kernel_type='Sparse')\n",
    "    \n",
    "    managers_sp = soap_calculator_sparse.transform(frames)\n",
    "    managers_train_sp = soap_calculator_sparse.transform(frames_train)\n",
    "    managers_test_sp = soap_calculator_sparse.transform(frames_test)\n",
    "    \n",
    "    cur_filter_sp = from_dict(to_dict(cur_filter))\n",
    "    cur_filter_sp._representation = soap_calculator_sparse\n",
    "    sparse_points = cur_filter_sp.transform(managers_sp)\n",
    "    \n",
    "    KNM = kernel_sparse(managers_train_sp, sparse_points)\n",
    "    model = train_gap_model(kernel_sparse, managers_train_sp, KNM, sparse_points, y_train, self_contributions, \n",
    "                        grad_train=None, lambdas=[7e-3, None], jitter=1e-8)\n",
    "\n",
    "    y_pred = model.predict(managers_test_sp)\n",
    "    score = get_score(y_pred, y_test)\n",
    "    score.update(n_features=int(n_features*fraction))\n",
    "    scores.append(score)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Make a map of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def link_ngl_wdgt_to_ax_pos(ax, pos, ngl_widget):\n",
    "    from matplotlib.widgets import AxesWidget\n",
    "    from scipy.spatial import cKDTree\n",
    "    r\"\"\"\n",
    "    Initial idea for this function comes from @arose, the rest is @gph82 and @clonker\n",
    "    \"\"\"\n",
    "    \n",
    "    kdtree = cKDTree(pos)        \n",
    "    #assert ngl_widget.trajectory_0.n_frames == pos.shape[0]\n",
    "    x, y = pos.T\n",
    "    \n",
    "    lineh = ax.axhline(ax.get_ybound()[0], c=\"black\", ls='--')\n",
    "    linev = ax.axvline(ax.get_xbound()[0], c=\"black\", ls='--')\n",
    "    dot, = ax.plot(pos[0,0],pos[0,1], 'o', c='red', ms=7)\n",
    "\n",
    "    ngl_widget.isClick = False\n",
    "    \n",
    "    def onclick(event):\n",
    "        linev.set_xdata((event.xdata, event.xdata))\n",
    "        lineh.set_ydata((event.ydata, event.ydata))\n",
    "        data = [event.xdata, event.ydata]\n",
    "        _, index = kdtree.query(x=data, k=1)\n",
    "        dot.set_xdata((x[index]))\n",
    "        dot.set_ydata((y[index]))\n",
    "        ngl_widget.isClick = True\n",
    "        ngl_widget.frame = index\n",
    "    \n",
    "    def my_observer(change):\n",
    "        r\"\"\"Here comes the code that you want to execute\n",
    "        \"\"\"\n",
    "        ngl_widget.isClick = False\n",
    "        _idx = change[\"new\"]\n",
    "        try:\n",
    "            dot.set_xdata((x[_idx]))\n",
    "            dot.set_ydata((y[_idx]))            \n",
    "        except IndexError as e:\n",
    "            dot.set_xdata((x[0]))\n",
    "            dot.set_ydata((y[0]))\n",
    "            print(\"caught index error with index %s (new=%s, old=%s)\" % (_idx, change[\"new\"], change[\"old\"]))\n",
    "    \n",
    "    # Connect axes to widget\n",
    "    axes_widget = AxesWidget(ax)\n",
    "    axes_widget.connect_event('button_release_event', onclick)\n",
    "    \n",
    "    # Connect widget to axes\n",
    "    ngl_widget.observe(my_observer, \"frame\", \"change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## make a map with kernel pca projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load the small molecules \n",
    "frames = read('../reference_data/inputs/small_molecules-1000.xyz',':600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=3.5, \n",
    "              max_radial=6, \n",
    "              max_angular=6, \n",
    "              gaussian_sigma_constant=0.4,\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              )\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap,name='Cosine', zeta=2, target_type='Structure', kernel_type='Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "managers = soap.transform(frames)\n",
    "\n",
    "Kmat = kernel(managers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kpca = KernelPCA(n_components=2,kernel='precomputed')\n",
    "kpca.fit(Kmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = kpca.transform(Kmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1],s=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## make an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# package to visualize the structures in the notebook\n",
    "# https://github.com/arose/nglview#released-version\n",
    "import nglview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iwdg = nglview.show_asetraj(frames)\n",
    "# set up the visualization\n",
    "iwdg.add_unitcell()\n",
    "iwdg.add_spacefill()\n",
    "iwdg.remove_ball_and_stick()\n",
    "iwdg.camera = 'orthographic'\n",
    "iwdg.parameters = { \"clipDist\": 0 }\n",
    "iwdg.center()\n",
    "iwdg.update_spacefill(radiusType='covalent',\n",
    "                                   scale=0.6,\n",
    "                                   color_scheme='element')\n",
    "iwdg._remote_call('setSize', target='Widget',\n",
    "                               args=['%dpx' % (600,), '%dpx' % (400,)])\n",
    "iwdg.player.delay = 200.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "link_ngl_wdgt_to_ax_pos(plt.gca(), X, iwdg)\n",
    "plt.scatter(X[:,0],X[:,1],s=3)\n",
    "iwdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
